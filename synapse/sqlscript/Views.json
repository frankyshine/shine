{
	"name": "Views",
	"properties": {
		"folder": {
			"name": "Synapse SQL/Serverless SQL Pools"
		},
		"content": {
			"query": "\n/* Views\n**************************************\n**************************************\nServerless SQL Pools supports the creation of SQL Views within a database which can then be queried exactly the same as\n a view in an Azure SQL database, Dedicated SQL Pool or a SQL Server instance. Views are useful in abstracting the \n syntax necessary to connect to data in an Azure Storage account or Cosmos DB. For example a Data Engineer could \n create a set of Views for Data Analysts and Business Intelligence Developers to use without those roles needing\nto understand the underlying source storage connections.\n\nFeatures and Functionality\n---------------------------\n. Create a query-able view in a Serverless SQL Pools database to abstract the connection to the data source\n. No need to define the columns or data types (schema information) at view creation time\n. Can embed the filepath() function as a column to allow source folder partition pruning\n\nUseful Scenarios\n-----------------\n. Needing to quickly create query-able objects over source data without explicitly stating schema\n. When source data is partitioned and is large enough that partition pruning is required\n. When only a specific set of columns are required to be exposed from the data source\n\n\nExample Syntax\n**************************************\nLet’s now look at several SQL View creation syntax examples to highlight the various options available when creating Views.\n\nThe following code creates a view without defining any column names or data types plus we use the full URL to the root \nfolder without requiring a DATA_SOURCE (URL to the Azure Storage account and Container) to be defined. The 2 * wildcards \nat the end of the BULK option tell Serverless SQL to traverse the folder structure. This is a quick and fast method of \ncreating a view.\n*/\n\n\nCREATE VIEW LDW.vwBlogSalesOrdersNoDataSource\nAS\nSELECT *\nFROM OPENROWSET(\n    BULK 'https://storage.dfs.core.windows.net/datalakehouse/sourcedata/salesorder/**',\n    FORMAT = 'CSV',\n    PARSER_VERSION = '2.0',\n    HEADER_ROW = TRUE,\n    FIELDTERMINATOR ='|' ) AS fct\n\n\n/*\nIn the following code we still don’t define any columns from the underlying data but this time we use a DATA_SOURCE. \nCreating a DATA_SOURCE with a base URL to Azure Storage means we can re-use that location across objects and just \nneed to define the folder structure rather than the full URL. We also use the filepath() function to create 3 columns\nin the View which will expose the name of the folder at the specified level. We can use these 3 columns in a WHERE clause\nto partition prune which will target only those folders required to satisfy the query.\n*/\n\n\nCREATE EXTERNAL DATA SOURCE ExternalDataSourceDataLake\n\tWITH (\n\t\tLOCATION   = 'https://storage.dfs.core.windows.net/datalakehouse' \n\t    );\n\nCREATE VIEW LDW.vwBlogSalesOrders\nAS\nSELECT *,\nCAST(fct.filepath(1) AS INT) AS FilePathYear,\nCAST(fct.filepath(2) AS TINYINT) AS FilePathMonth,\nCAST(fct.filepath(3) AS DATE) AS FilePathDate\nFROM \nOPENROWSET \n(\n    BULK 'sourcedata/salesorder/OrderYear=*/OrderMonth=*/OrderDatePartition=*/*.csv',\n    DATA_SOURCE = 'ExternalDataSourceDataLake',\n    FORMAT = 'CSV',\n    PARSER_VERSION = '2.0',\n    HEADER_ROW = TRUE,\n    FIELDTERMINATOR ='|'\n) AS fct\n\n\n/*\nIn this next code segment we are now defining columns we would like to expose, as our example data has a header row we use \nthe HEADER_ROW = TRUE option then we are able to define column names in the SELECT statement. Notice that we still do not\n define any data types, just the column name as Serverless SQL will derive the data type automatically.\n*/\n\n\nCREATE VIEW LDW.vwBlogSalesOrdersColumns\nAS\nSELECT OrderID,\n        CustomerID,\n        OrderDate\nFROM \nOPENROWSET \n(\n    BULK 'sourcedata/salesorder/**',\n    DATA_SOURCE = 'ExternalDataSourceDataLake',\n    FORMAT = 'CSV',\n    PARSER_VERSION = '2.0',\n    HEADER_ROW = TRUE,\n    FIELDTERMINATOR ='|'\n) AS fct\n\n/*\nAlthough deriving data types automatically is useful, it can introduce inefficiency as Serverless SQL may choose a \ndata type with a byte size far large than the actual data type and therefore increase data processed costs.\n\nWe can also use the WITH option to add schema definition to the view. In the code example below we use WITH to \ndefine the columns we would like to select from the source files and also define the data type.\n*/\n\n\nCREATE VIEW LDW.vwBlogSalesOrdersWith\nAS\nSELECT * FROM \nOPENROWSET \n(\n    BULK 'sourcedata/salesorder/**',\n    DATA_SOURCE = 'ExternalDataSourceDataLake',\n    FORMAT = 'CSV',\n    PARSER_VERSION = '2.0',\n    HEADER_ROW = TRUE,\n    FIELDTERMINATOR ='|'\n)\nWITH\n(\n    OrderID INT,\n    CustomerID INT,\n    OrderDate DATE\n) AS fct\n\n\n/*\nIf our source data does not contain a header row we can still define column names and assign data types, we now use \nthe FIRSTROW option to tell Serverless SQL where the first row of data is located. In the WITH option we define \ncolumn names, data types, and the position within the source files (E.G. first column is 1).\n*/\n\nCREATE VIEW LDW.vwBlogSalesOrdersWithPosition\nAS\nSELECT * FROM \nOPENROWSET \n(\n    BULK 'sourcedata/salesorder/**',\n    DATA_SOURCE = 'ExternalDataSourceDataLake',\n    FORMAT = 'CSV',\n    PARSER_VERSION = '2.0',\n    FIRSTROW = 1,\n    FIELDTERMINATOR ='|'\n)\nWITH\n(\n    OrderID INT 1,\n    CustomerID INT 2,\n    OrderDate DATE 7\n) AS fct",
			"metadata": {
				"language": "sql"
			},
			"currentConnection": {
				"databaseName": "master",
				"poolName": "Built-in"
			},
			"resultLimit": 5000
		},
		"type": "SqlQuery"
	}
}